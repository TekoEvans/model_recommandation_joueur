{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.882352941176471,
  "eval_steps": 5,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 2.167379140853882,
      "learning_rate": 2.4e-05,
      "loss": 2.5807,
      "step": 5
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.2801060676574707,
      "learning_rate": 2.275e-05,
      "loss": 2.5055,
      "step": 10
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 2.384880304336548,
      "learning_rate": 2.15e-05,
      "loss": 2.5012,
      "step": 15
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.318702220916748,
      "learning_rate": 2.025e-05,
      "loss": 2.4193,
      "step": 20
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 2.2958202362060547,
      "learning_rate": 1.9e-05,
      "loss": 2.391,
      "step": 25
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.209703207015991,
      "learning_rate": 1.775e-05,
      "loss": 2.3315,
      "step": 30
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 2.4135000705718994,
      "learning_rate": 1.65e-05,
      "loss": 2.2475,
      "step": 35
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 2.320035934448242,
      "learning_rate": 1.525e-05,
      "loss": 2.248,
      "step": 40
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 2.419931411743164,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 2.186,
      "step": 45
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.7761082649230957,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 2.1389,
      "step": 50
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 2.614546775817871,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 2.1198,
      "step": 55
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 2.543278455734253,
      "learning_rate": 1.025e-05,
      "loss": 2.0661,
      "step": 60
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 2.641573429107666,
      "learning_rate": 9e-06,
      "loss": 2.0233,
      "step": 65
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 2.729592800140381,
      "learning_rate": 7.75e-06,
      "loss": 2.0004,
      "step": 70
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 2.657027244567871,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 1.9515,
      "step": 75
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 2.596081256866455,
      "learning_rate": 5.25e-06,
      "loss": 1.9628,
      "step": 80
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.615452766418457,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.9157,
      "step": 85
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 2.8348984718322754,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 1.9461,
      "step": 90
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 2.7134902477264404,
      "learning_rate": 1.5e-06,
      "loss": 1.8893,
      "step": 95
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.787604570388794,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 1.8669,
      "step": 100
    }
  ],
  "logging_steps": 5,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1264639231918080.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
